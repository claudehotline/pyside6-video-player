{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.model import parsingNet\n",
    "from torch.onnx import export\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "from data.constant import culane_row_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\deeplane\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\deeplane\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "net = parsingNet(pretrained = False, backbone='18',cls_dim = (201,18,4),use_aux=False) # we dont need auxiliary segmentation in testing\n",
    "\n",
    "state_dict = torch.load('checkpoints/culane_18.pth', map_location='cpu')['model']\n",
    "compatible_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "  if 'module.' in k:\n",
    "    compatible_state_dict[k[7:]] = v\n",
    "  else:\n",
    "    compatible_state_dict[k] = v\n",
    "\n",
    "net.load_state_dict(compatible_state_dict, strict=False)\n",
    "# 设置模型为推理模式\n",
    "net.eval()\n",
    "\n",
    "x = torch.randn(1, 3, 288, 800)\n",
    "torch_out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "export(net, x, 'culane_18.onnx', verbose=True, input_names=['input'], output_names=['output'], opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('culane_18.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "# onnx_model = onnx.load(\"test.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"culane_18.onnx\")\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 288, 800])\n",
      "(201, 18, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# img_path = 'I:/Ultra-Fast-Lane-Detection/CULane/driver_37_30frame/05181432_0203.MP4/04320.jpg'\n",
    "img_path = 'D:/Projects/deeplearning/data/CULane/driver_23_30frame/05151640_0419.MP4/00000.jpg'\n",
    "\n",
    "img = Image.open(img_path)\n",
    "# print(type(img))\n",
    "# image = np.asarray(img, dtype=np.float32)\n",
    "# image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "        transforms.Resize((288, 800)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "\n",
    "image = img_transforms(img).unsqueeze(0)\n",
    "print(image.shape)\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "ort_outs = ort_outs[0][0]\n",
    "# print(ort_outs)\n",
    "\n",
    "print(ort_outs.shape)\n",
    "\n",
    "img_w, img_h = 1640, 590\n",
    "row_anchor = culane_row_anchor\n",
    "cls_num_per_lane = 18\n",
    "\n",
    "col_sample = np.linspace(0, 800 - 1, 200)\n",
    "col_sample_w = col_sample[1] - col_sample[0]\n",
    "\n",
    "ort_outs = ort_outs[:, ::-1, :]\n",
    "prob = scipy.special.softmax(ort_outs[:-1, :, :], axis=0)\n",
    "idx = np.arange(200) + 1\n",
    "idx = idx.reshape(-1, 1, 1)\n",
    "loc = np.sum(prob * idx, axis=0)\n",
    "out_j = np.argmax(ort_outs, axis=0)\n",
    "loc[out_j == 200] = 0\n",
    "out_j = loc\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "vis = cv2.imread(img_path)\n",
    "for i in range(out_j.shape[1]):\n",
    "    if np.sum(out_j[:, i] != 0) > 2:\n",
    "        for k in range(out_j.shape[0]):\n",
    "            if out_j[k, i] > 0:\n",
    "                ppp = (int(out_j[k, i] * col_sample_w * img_w / 800) - 1, int(img_h * (row_anchor[cls_num_per_lane-1-k]/288)) - 1 )\n",
    "                cv2.circle(vis,ppp,5,(0,255,0),-1)\n",
    "cv2.imwrite('result.jpg', vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger()\n",
    "onnx_file_path = 'culane_18.onnx'\n",
    "engine_file_path = 'culane_18.engine'\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "IN_H = 288\n",
    "IN_W = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_22372\\1327851646.py:22: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 1 << 30\n",
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_22372\\1327851646.py:25: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    }
   ],
   "source": [
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(EXPLICIT_BATCH)\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "# parse onnx\n",
    "if isinstance(onnx_file_path, str):\n",
    "  parse_valid = parser.parse_from_file(onnx_file_path)\n",
    "elif isinstance(onnx_file_path, onnx.ModelProto):\n",
    "  parse_valid = parser.parse(onnx_file_path.SerializeToString())\n",
    "else:\n",
    "  raise TypeError('Unsupported onnx model type!')\n",
    "\n",
    "if not parse_valid:\n",
    "  error_msgs = ''\n",
    "  for error in range(parser.num_errors):\n",
    "    error_msgs += f'{parser.get_error(error)}\\n'\n",
    "  raise RuntimeError(f'Failed to parse onnx, {error_msgs}')\n",
    "\n",
    "# config builder\n",
    "config = builder.create_builder_config()\n",
    "config.max_workspace_size = 1 << 30\n",
    "\n",
    "profile = builder.create_optimization_profile()\n",
    "profile.set_shape_input('input', *[[BATCH_SIZE, 3, IN_H, IN_W]]*3)\n",
    "if config.add_optimization_profile(profile) < 0:\n",
    "  TRT_LOGGER.warning(f'Invalid optimization profile {profile}.')\n",
    "\n",
    "# config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "engine = builder.build_engine(network, config)\n",
    "assert engine is not None, 'Failed to create TensorRT engine'\n",
    "# save(engine, output_file_prefix + '.engine')\n",
    "with open(engine_file_path, mode='wb') as f:\n",
    "  if isinstance(engine, trt.ICudaEngine):\n",
    "    engine = engine.serialize()\n",
    "  f.write(bytearray(engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGINE_PATH='/content/drive/MyDrive/model/culane_18.engine'\n",
    "trt_logger = trt.Logger(trt.Logger.INFO)\n",
    "runtime = trt.Runtime(trt_logger)\n",
    "with open(ENGINE_PATH, \"rb\") as f:\n",
    "  engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = engine.create_execution_context()\n",
    "\n",
    "INPUT_DATA_TYPE = np.float32\n",
    "stream = cuda.Stream()\n",
    "host_in = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=INPUT_DATA_TYPE)\n",
    "host_out = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=INPUT_DATA_TYPE)\n",
    "\n",
    "device_in = cuda.mem_alloc(host_in.nbytes)\n",
    "device_out = cuda.mem_alloc(host_out.nbytes)\n",
    "bindings = [int(device_in), int(device_out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_anchor = culane_row_anchor\n",
    "cls_num_per_lane = 18\n",
    "col_sample = np.linspace(0, 800 - 1, 200)\n",
    "col_sample_w = col_sample[1] - col_sample[0]\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "  transforms.Resize((288, 800)),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "  return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/content/drive/MyDrive/data/test_img/05220.jpg'\n",
    "\n",
    "img = Image.open(image_path)\n",
    "img = img_transforms(img).unsqueeze(0)\n",
    "np.copyto(host_in, img.ravel())\n",
    "cuda.memcpy_htod_async(device_in, host_in, stream)\n",
    "context.execute_async_v2(bindings, stream.handle)\n",
    "cuda.memcpy_dtoh_async(host_out, device_out, stream)\n",
    "stream.synchronize()\n",
    "ort_outs = host_out.reshape(201,18,4)\n",
    "ort_outs = ort_outs[:, ::-1, :]\n",
    "prob = scipy.special.softmax(ort_outs[:-1, :, :], axis=0)\n",
    "idx = np.arange(200) + 1\n",
    "idx = idx.reshape(-1, 1, 1)\n",
    "loc = np.sum(prob * idx, axis=0)\n",
    "out_j = np.argmax(ort_outs, axis=0)\n",
    "loc[out_j == 200] = 0\n",
    "out_j = loc\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "img_h, img_w = image.shape[:2]\n",
    "for i in range(out_j.shape[1]):\n",
    "  if np.sum(out_j[:, i] != 0) > 2:\n",
    "    for k in range(out_j.shape[0]):\n",
    "      if out_j[k, i] > 0:\n",
    "        ppp = (int(out_j[k, i] * col_sample_w * img_w / 800) - 1, int(img_h * (row_anchor[cls_num_per_lane-1-k]/288)) - 1 )\n",
    "        cv2.circle(image,ppp,5,(0,255,0),-1)\n",
    "cv2.imwrite('/content/result.jpg', image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
